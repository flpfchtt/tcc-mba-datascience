{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "acoes = ['MGLU3', 'HAPV3', 'B3SA3', 'BBDC4', 'CPLE6', 'BEEF3', 'PETR4', 'BRFS3', 'ABEV3', 'ITUB4', 'CSAN3', 'LREN3', 'COGN3', 'PCAR3', 'GGBR4', 'BRKM5', 'CIEL3', 'RAIZ4', 'USIM5', 'GOAU4', 'VALE3', 'ITSA4',\n",
    "'CMIG4', 'CVCB3', 'POMO4', 'BHIA3', 'PRIO3', 'MRFG3', 'AZUL4', 'PETZ3', 'BBAS3', 'ENEV3', 'RAIL3', 'EQTL3', 'VAMO3', 'MRVE3', 'BBDC3', 'SOMA3', 'JBSS3', 'CPLE3', 'BRSR6', 'PETR3', 'LJQQ3', 'ASAI3', 'CMIN3',\n",
    "'CCRO3', 'MTRE3', 'RDOR3', 'BBSE3', 'VBBR3', 'RENT3', 'AURE3', 'NTCO3', 'CSNA3', 'MULT3', 'UGPA3', 'SRNA3', 'ECOR3', 'STBP3', 'HBSA3', 'TIMS3', 'EMBR3', 'TTEN3', 'IFCM3', 'CBAV3', 'ALOS3', 'YDUQ3', 'ANIM3', 'KRSA3',\n",
    "'SIMH3', 'GOLL4', 'SAPR4', 'CEAB3', 'VIVA3', 'VVEO3', 'CXSE3', 'ELET3', 'GMAT3', 'CRFB3', 'AMER3', 'JHSF3', 'BRAP4', 'AZEV4', 'RADL3', 'DXCO3', 'RRRP3', 'OIBR3', 'QUAL3', 'LWSA3', 'AERI3', 'TEND3', 'SUZB3', 'CYRE3',\n",
    "'SEQL3', 'WEGE3', 'SBSP3', 'EZTC3', 'GUAR3', 'MOVI3', 'RECV3', 'TOTS3', 'RAPT4', 'ONCO3', 'SLCE3', 'TRPL4', 'EGIE3', 'AESB3', 'INTB3', 'VIVT3', 'ARZZ3', 'FLRY3', 'GFSA3', 'ENAT3', 'KLBN4', 'CLSA3', 'CURY3', 'MLAS3',\n",
    "'DIRR3', 'ALPA4', 'CSMG3', 'POSI3', 'GGPS3', 'NEOE3', 'RCSL3', 'SMFT3', 'PSSA3', 'HYPE3', 'LUPA3', 'SBFG3', 'ODPV3', 'SMTO3', 'PORT3', 'CASH3', 'ZAMP3', 'IRBR3', 'BPAN4', 'MEAL3', 'CPFE3', 'RCSL4', 'MBLY3', 'NGRD3',\n",
    "'PLPL3', 'KEPL3', 'PNVL3', 'ENJU3', 'LIGT3', 'JALL3', 'ARML3', 'GRND3', 'ELET6', 'FESA4', 'MYPK3', 'AMBP3', 'ESPA3', 'SAPR3', 'PDGR3', 'ABCB4', 'OPCT3', 'MILS3', 'CAML3', 'USIM3', 'RANI3', 'LAVV3', 'MDIA3', 'POMO3',\n",
    "'PGMN3', 'EVEN3', 'BMGB4', 'DASA3', 'PRNR3', 'KLBN3', 'CMIG3', 'ORVR3', 'FIQE3', 'AZEV3', 'SOJA3', 'TASA4', 'MATD3', 'MDNE3', 'BMOB3', 'HBOR3', 'PTBL3', 'SHUL4', 'VULC3', 'VITT3', 'TRIS3', 'JSLG3', 'LEVE3', 'HBRE3',\n",
    "'SGPS3', 'TAEE4', 'SEER3', 'BRIT3', 'TUPY3', 'WIZC3', 'AMAR3', 'AGXY3', 'VLID3', 'ROMI3', 'AGRO3', 'RNEW4', 'MELK3', 'PINE4', 'BLAU3', 'TRAD3', 'CSED3', 'TAEE3', 'TGMA3', 'ITUB3', 'UNIP6', 'SANB4', 'DESK3', 'ALPK3',\n",
    "'SYNE3', 'FRAS3', 'ITSA3', 'SANB3', 'PFRM3', 'CTNM4', 'LOGG3', 'CAMB3', 'ETER3', 'AALR3', 'ALLD3', 'TFCO4', 'GOAU3', 'GGBR3', 'BRKM3', 'DMVF3', 'SHOW3', 'BIOM3', 'TECN3', 'DEXP3', 'BRAP3', 'CSUD3', 'PMAM3', 'ELMD3',\n",
    "'RNEW3', 'RSID3', 'IGTI3', 'IGTI3', 'INEP3', 'OIBR4', 'TPIS3', 'EUCA4', 'LPSB3', 'MNPR3', 'TCSA3', 'LOGN3', 'CTSA4', 'ALUP4', 'JFEN3', 'PDTC3', 'INEP4', 'LAND3', 'BRSR3', 'UCAS3', 'EMAE4', 'BMEB4', 'BEES3', 'TASA3',\n",
    "'HAGA4', 'WEST3', 'RAPT3', 'DOTZ3', 'SCAR3', 'ALUP3', 'ENGI4', 'NINJ3', 'VIVR3', 'CGRA3', 'CRPG5', 'LVTC3', 'ATOM3', 'WHRL4', 'CEBR3', 'NUTR3', 'UNIP3', 'OFSA3', 'ENGI3', 'COCE5', 'FIEI3', 'CEBR5', 'CLSC4', 'CGRA4',\n",
    "'ATMP3', 'CRPG6', 'CEBR6', 'CTSA3', 'BPAC3', 'DEXP4', 'BAHI3', 'RDNI3', 'OSXB3', 'PLAS3', 'BOBR4', 'HOOT4', 'BEES4', 'BPAC5', 'MAPT3', 'VSTE3', 'MAPT4', 'BAZA3', 'MTSA4', 'FHER3', 'TRPL3', 'CTKA4', 'EQPA3', 'EPAR3',\n",
    "'WLMM4', 'SNSY5', 'CEDO4', 'RSUL4', 'GEPA4', 'TELB4', 'ALPA3', 'PINE3', 'MGEL4', 'MERC4', 'HAGA3', 'PTNT4', 'REDE3', 'HETA4', 'NEXP3', 'MOAR3', 'HBTS5', 'RPMG3', 'CGAS5', 'MNDL3', 'BMEB3', 'SNSY3', 'RPAD3', 'AFLT3',\n",
    "'WHRL3', 'DOHL4', 'APER3', 'BGIP4', 'CPLE5', 'TELB3', 'AVLL3', 'CEEB3', 'CSRN3', 'BSLI4', 'BSLI3', 'EALT3', 'BAUH4', 'PEAB3', 'EKTR4', 'CEEB5', 'CEDO3', 'EQMA3B', 'EUCA3', 'EALT4', 'IGTI4', 'IGTI4', 'BMKS3', 'RPAD5',\n",
    "'MRSA5B', 'PEAB4', 'MRSA6B', 'BDLL4', 'CGAS3', 'GEPA3', 'NORD3', 'MRSA3B', 'BMIN4', 'PTNT3', 'MTSA3', 'FESA3', 'BALM4', 'DOHL3', 'RPAD6', 'TKNO4', 'AHEB5', 'CBEE3', 'MWET4', 'SOND6', 'AHEB3', 'BRKM6', 'BALM3', 'ESTR4',\n",
    "'EQPA7', 'BRSR5', 'EQPA5', 'ENMT3', 'SOND5', 'BGIP3', 'CEED3', 'CLSC3', 'DTCY3', 'EMAE3', 'UNIP5', 'LIPR3', 'GSHP3', 'LUXM4', 'BDLL3', 'CTNM3', 'CSRN6', 'WLMM3']\n",
    "\n",
    "df_acoes = pd.DataFrame({\n",
    "    'Ticker': acoes\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração inicial dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acoes['Ticker'] = df_acoes['Ticker'] + '.SA' \n",
    "lista_acoes = df_acoes['Ticker'].to_list()\n",
    "lista_acoes = set(lista_acoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['Date','Close','Ticker'])\n",
    "for i in lista_acoes:\n",
    "    data = yf.download(i, start = \"2021-01-01\", end = \"2022-12-31\")\n",
    "    data = data.reset_index()\n",
    "    data = data[['Date', 'Close']]\n",
    "    data['Ticker'] = i\n",
    "    df = pd.concat([df, data])\n",
    "    \n",
    "df.dropna(inplace = True)\n",
    "df['Ticker'] = df['Ticker'].apply(lambda x: x.split('.')[0])\n",
    "df.to_csv('base_treino.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = pd.DataFrame(columns = ['Date','Close','Ticker'])\n",
    "for i in lista_acoes:\n",
    "    data = yf.download(i, start = \"2023-01-01\", end = \"2024-06-01\")\n",
    "    data = data.reset_index()\n",
    "    data = data[['Date', 'Close']]\n",
    "    data['Ticker'] = i\n",
    "    df_teste = pd.concat([df_teste, data])\n",
    "    \n",
    "df_teste.dropna(inplace = True)\n",
    "df_teste['Ticker'] = df_teste['Ticker'].apply(lambda x: x.split('.')[0])\n",
    "df_teste.to_csv('base_teste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('base_treino.csv')\n",
    "df.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "df_teste = pd.read_csv('base_teste.csv')\n",
    "df_teste.drop(columns = ['Unnamed: 0'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tratamento utilizando a distância interquartil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retorna_lista_parametros(df):\n",
    "\n",
    "        lista_parametros = pd.DataFrame(columns = ['Ticker', 'primeiro_quartil', 'mediana', 'terceiro_quartil', 'IQR', 'valor_minimo', 'valor_maximo', 'std', 'media'])\n",
    "\n",
    "        df_prio3 = df[df['Ticker'] == 'PRIO3']\n",
    "        df_prio3 = df_prio3[['Date', 'Close']]\n",
    "        df_prio3 = df_prio3.set_index('Date')\n",
    "\n",
    "        for i in df['Ticker'].unique():\n",
    "\n",
    "                df_temp = df[df['Ticker'] == i]\n",
    "                primeiro_quartil = np.quantile(df_temp['Close'], 0.25)\n",
    "                mediana = np.quantile(df_temp['Close'], 0.5)\n",
    "                terceiro_quartil = np.quantile(df_temp['Close'], 0.75)\n",
    "                IQR = terceiro_quartil - primeiro_quartil\n",
    "                valor_minimo = primeiro_quartil - 1.5 * IQR\n",
    "                valor_maximo = terceiro_quartil + 1.5 * IQR\n",
    "                std = df_temp['Close'].std()\n",
    "                media = df_temp['Close'].mean()\n",
    "                qtd_registros = df_temp.shape[0]\n",
    "\n",
    "                df_temp = df_temp[['Date', 'Close']]\n",
    "                df_temp = df_temp.set_index('Date')\n",
    "\n",
    "                corr_prio3 = df_temp['Close'].corr(df_prio3['Close'])\n",
    "\n",
    "                lista_parametros = lista_parametros._append({'Ticker' : i, 'primeiro_quartil' : primeiro_quartil, 'mediana' : mediana, 'terceiro_quartil' : terceiro_quartil,'IQR' : IQR, 'valor_minimo' : valor_minimo, 'valor_maximo' : valor_maximo, 'std' : std, 'media' : media, 'cv' : std / media, 'qtd_registros' : qtd_registros , 'corr_prio3' : corr_prio3}, ignore_index = True)\n",
    "    \n",
    "        lista_parametros['valor_minimo'] = np.where(lista_parametros['valor_minimo'] < 0, 0, lista_parametros['valor_minimo'])\n",
    "        lista_parametros['corr_prio3'] = lista_parametros['corr_prio3'].fillna(0)\n",
    "\n",
    "        return lista_parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_parametros_outliers = retorna_lista_parametros(df)\n",
    "lista_parametros_outliers = lista_parametros_outliers[['Ticker' ,'valor_minimo', 'valor_maximo']]\n",
    "df = df.merge(lista_parametros_outliers, how = 'left', on = 'Ticker')\n",
    "\n",
    "df_removido_outlier = df[(df['Close'] >= df['valor_minimo']) * (df['Close'] <= df['valor_maximo']) != 1]\n",
    "\n",
    "df = df[(df['Close'] >= df['valor_minimo']) * (df['Close'] <= df['valor_maximo'])]\n",
    "df.drop(['valor_minimo', 'valor_maximo'], axis = 1, inplace = True)\n",
    "\n",
    "lista_parametros_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de ações com baixo número de registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qntd_registros = df.groupby(['Ticker']).agg({'Date' : 'count'}).reset_index()\n",
    "qntd_registros.rename(columns = {'Date' : 'count'}, inplace = True)\n",
    "\n",
    "corte = 0.9\n",
    "volume_minimo = 250 * 2 * corte\n",
    "print(f'Quantidade mínima de registros {volume_minimo}')\n",
    "\n",
    "qntd_n_registros = qntd_registros[qntd_registros['count'] < volume_minimo]\n",
    "qntd_registros = qntd_registros[qntd_registros['count'] >= volume_minimo]\n",
    "\n",
    "acoes_com_volume_minimo = qntd_registros['Ticker'].to_list()\n",
    "\n",
    "df = df[df['Ticker'].isin(acoes_com_volume_minimo)]\n",
    "\n",
    "\n",
    "print(f'Quantidade de ações removidas: {qntd_n_registros.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_parametros = retorna_lista_parametros(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = lista_parametros[['cv', 'corr_prio3']]\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "wcss3 = list()\n",
    "for n_grupos in range(1, 15):\n",
    "    km = KMeans(n_clusters = n_grupos, init = 'k-means++', random_state = 0).fit(features_scaled)\n",
    "    wcss3.append(km.inertia_)\n",
    "sns.lineplot(x = range(1, 15), y = wcss3)\n",
    "plt.xticks(range(1, 15))  \n",
    "plt.axvline(x=3, color='red', linestyle='--')\n",
    "\n",
    "plt.xlabel('Número de clusters')\n",
    "plt.ylabel('Soma dos quadrados dentro dos clusters (WCSS)')\n",
    "plt.savefig('img_02_cotovelo.jpeg', format = 'jpeg', dpi = 600)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "noofclusters = [2, 3,4,5,6,7,8]\n",
    "silhueta = []\n",
    "for clusters in range(2,15):\n",
    "    km = KMeans(n_clusters = clusters, init = 'k-means++', random_state = 0)\n",
    "    cluster_labels = km.fit_predict(features_scaled)\n",
    "    silhouette_avg = silhouette_score(features_scaled, cluster_labels)\n",
    "    silhueta.append(silhouette_avg)\n",
    "\n",
    "sns.lineplot(x = range(2, 15), y = silhueta)\n",
    "\n",
    "plt.xticks(range(2, 15))  \n",
    "plt.axvline(x=3, color='red', linestyle='--')\n",
    "\n",
    "plt.xlabel('Número de clusters')\n",
    "plt.ylabel('Score da silhueta')\n",
    "plt.savefig('img_03_silhueta.jpeg', format = 'jpeg', dpi = 600)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_encontrado = 3\n",
    "kmeans = KMeans(n_clusters = k_encontrado, init = 'k-means++', random_state = 0).fit(features_scaled)\n",
    "lista_parametros['Cluster'] = kmeans.fit_predict(features_scaled)\n",
    "\n",
    "sns.scatterplot(data = lista_parametros, x='cv', y='corr_prio3', hue = 'Cluster', palette='Set2')\n",
    "\n",
    "plt.xlabel('Coeficiente de Variação (CV)')\n",
    "plt.ylabel('Correlação com PRIO3')\n",
    "\n",
    "legend_labels = {0: 'Cluster 1', 1: 'Cluster 3', 2: 'Cluster 2'}\n",
    "handles, _ = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles=[handles[i] for i in legend_labels.keys()], labels=list(legend_labels.values()), title='Clusters')\n",
    "plt.savefig('img_04_kmeans.jpeg', format = 'jpeg', dpi = 600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encontrar hiperparametros por grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "class LSTMRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, neurons=50, dropout_rate=0.2, batch_size=32, epochs=50):\n",
    "        self.neurons = neurons\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.model = None\n",
    "\n",
    "    def create_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(self.neurons, return_sequences=True, input_shape=(60, 1)))\n",
    "        model.add(Dropout(self.dropout_rate))\n",
    "        model.add(LSTM(self.neurons, return_sequences=False))\n",
    "        model.add(Dropout(self.dropout_rate))\n",
    "        model.add(Dense(25))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        print(f'neurons: {self.neurons} dropout: {self.dropout_rate} batch_size: {self.batch_size} epochs: {self.epochs}')\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model = self.create_model()\n",
    "        early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
    "        self.model.fit(X, y, batch_size=self.batch_size, epochs=self.epochs, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "\n",
    "lista_acoes_modelo = ['PETR4', 'ITUB4', 'MGLU3']\n",
    "texto_resultado = []\n",
    "\n",
    "param_grid = {\n",
    "    'neurons': [25, 50, 75],\n",
    "    'dropout_rate': [0.1, 0.2, 0.3],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [25, 50, 75]\n",
    "}\n",
    "\n",
    "model = LSTMRegressor()\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3, n_jobs = -1)\n",
    "\n",
    "cont = 0\n",
    "for k in lista_acoes_modelo:\n",
    "    nome = k\n",
    "    cont += 1\n",
    "    print(f'{cont} {nome}')\n",
    "    \n",
    "    df_temp = df[df['Ticker'] == nome][['Date', 'Close']].sort_values(by='Date')\n",
    "    df_temp = df_temp.set_index('Date')\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_train_data = scaler.fit_transform(df_temp)\n",
    "\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(60, len(scaled_train_data)):\n",
    "        x_train.append(scaled_train_data[i-60:i, 0])\n",
    "        y_train.append(scaled_train_data[i, 0])\n",
    "\n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "\n",
    "    grid_result = grid.fit(x_train, y_train)\n",
    "    \n",
    "    txt = f'Melhores parâmetros {nome}: {grid_result.best_params_}'\n",
    "    texto_resultado.append(txt)\n",
    "\n",
    "df_hiperparametros = pd.DataFrame(columns=['Ticker', 'batch_size', 'dropout_rate', 'epochs', 'neurons'])\n",
    "for i in range(0, len(texto_resultado)):\n",
    "    hip = '{' + texto_resultado[i].split(\": {\")[1]\n",
    "    hip_split = hip.split(',')\n",
    "    acao = texto_resultado[i].split(' ')[2].split(':')[0]\n",
    "    batch_size = int(hip_split[0].split(': ')[1])\n",
    "    dropout_rate = float(hip_split[1].split(': ')[1])\n",
    "    epochs = int(hip_split[2].split(': ')[1])\n",
    "    neurons = int(hip_split[3].split(': ')[1].split('}')[0])\n",
    "\n",
    "    df_hiperparametros.loc[len(df_hiperparametros)] = {\n",
    "            'Ticker': acao,\n",
    "            'batch_size': batch_size,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'epochs': epochs,\n",
    "            'neurons': neurons\n",
    "        }\n",
    "\n",
    "df_hiperparametros.to_csv('df_hiperparametros.csv')\n",
    "df_hiperparametros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hiperparametros = pd.read_csv('df_hiperparametros.csv', index_col = 0)\n",
    "df_hiperparametros = pd.merge(df_hiperparametros, lista_parametros[['Ticker', 'Cluster']], on='Ticker', how='inner')\n",
    "df_hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hiperparametros.drop(columns=['Ticker'], inplace = True)\n",
    "lista_parametros = pd.merge(lista_parametros, df_hiperparametros, on='Cluster', how = 'inner')\n",
    "lista_parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def treina_modelo(row):\n",
    "    nome = row['Ticker']\n",
    "    n_batch = row['batch_size']\n",
    "    taxa_dropout = row['dropout_rate']\n",
    "    n_epoch = row['epochs']\n",
    "    n_neurons = row['neurons']\n",
    "    cluster = row['Cluster']\n",
    "\n",
    "    print(f'Treinando {nome}')\n",
    "    df_temp = df[df['Ticker'] == nome][['Date', 'Close']].sort_values(by='Date')\n",
    "    df_temp = df_temp.set_index('Date')\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_train_data = scaler.fit_transform(df_temp)\n",
    "\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(60, len(scaled_train_data)):\n",
    "        x_train.append(scaled_train_data[i-60:i, 0])\n",
    "        y_train.append(scaled_train_data[i, 0])\n",
    "\n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_neurons, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "    model.add(Dropout(taxa_dropout))\n",
    "    model.add(LSTM(n_neurons, return_sequences=False))\n",
    "    model.add(Dropout(taxa_dropout))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
    "    model.fit(x_train, y_train, batch_size=n_batch, epochs=n_epoch, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    y_train_predict = model.predict(x_train)\n",
    "    y_train_predict = scaler.inverse_transform(y_train_predict)\n",
    "\n",
    "    resultados_temp = []\n",
    "    for i in range(len(y_train_predict)):\n",
    "        resultados_temp.append({\n",
    "            'Data': df_temp.index[i + 60],\n",
    "            'Nome da Ação': nome,\n",
    "            'Cluster': cluster,\n",
    "            'Valor Real': scaler.inverse_transform([[y_train[i]]])[0][0],\n",
    "            'Origem': 'Treinamento',\n",
    "            'Valor Predito': y_train_predict[i][0]\n",
    "        })\n",
    "\n",
    "    df_temp_teste = df_teste[df_teste['Ticker'] == nome][['Date', 'Close']].sort_values(by='Date')\n",
    "    df_temp_teste = df_temp_teste.set_index('Date')\n",
    "    scaled_data_teste = scaler.transform(df_temp_teste)\n",
    "\n",
    "    x_teste = []\n",
    "    y_teste = []\n",
    "    for i in range(60, len(scaled_data_teste)):\n",
    "        x_teste.append(scaled_data_teste[i-60:i, 0])\n",
    "        y_teste.append(scaled_data_teste[i, 0])\n",
    "\n",
    "    x_teste, y_teste = np.array(x_teste), np.array(y_teste)\n",
    "    x_teste = np.reshape(x_teste, (x_teste.shape[0], x_teste.shape[1], 1))\n",
    "\n",
    "    y_teste_predict = model.predict(x_teste)\n",
    "    y_teste_predict = scaler.inverse_transform(y_teste_predict)\n",
    "\n",
    "    for i in range(len(y_teste_predict)):\n",
    "        resultados_temp.append({\n",
    "            'Data': df_temp_teste.index[i + 60],\n",
    "            'Nome da Ação': nome,\n",
    "            'Cluster': cluster,\n",
    "            'Valor Real': scaler.inverse_transform([[y_teste[i]]])[0][0],\n",
    "            'Origem': 'Teste',\n",
    "            'Valor Predito': y_teste_predict[i][0]\n",
    "        })\n",
    "\n",
    "    return resultados_temp\n",
    "\n",
    "df_resultados = pd.DataFrame(columns=['Data', 'Nome da Ação', 'Cluster', 'Valor Real', 'Origem', 'Valor Predito'])\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:  \n",
    "    resultados_futuros = [executor.submit(treina_modelo, row) for index, row in lista_parametros.iterrows()]\n",
    "    for future in resultados_futuros:\n",
    "        resultados_temp = future.result()\n",
    "        df_resultados = pd.concat([df_resultados, pd.DataFrame(resultados_temp)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados.to_csv('df_resultados.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
